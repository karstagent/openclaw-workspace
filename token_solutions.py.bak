#!/usr/bin/env python3
"""
Production wrapper for token limit solutions.
Combines semantic compression and context extension.
"""

import os
import sys
import json
import logging
from typing import Dict, Any, List, Optional, Union
import time
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("logs/token_solutions.log")
    ]
)
logger = logging.getLogger("token-solutions")

# Determine base directories
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_DIR = os.path.join(os.path.dirname(SCRIPT_DIR), "config")
LOG_DIR = os.path.join(os.path.dirname(SCRIPT_DIR), "logs")
os.makedirs(LOG_DIR, exist_ok=True)

# Load configuration
CONFIG_PATH = os.path.join(CONFIG_DIR, "token_solutions.json")
try:
    with open(CONFIG_PATH, 'r') as f:
        CONFIG = json.load(f)
except Exception as e:
    logger.error(f"Error loading configuration: {e}")
    CONFIG = {
        "semantic_compression": {"enabled": True, "default_compression_ratio": 6},
        "context_extension": {"enabled": True, "target_context_length": 400000},
        "monitoring": {"log_level": "info", "track_token_savings": True}
    }

# Import solution modules
try:
    from semantic_compression import SemanticCompressor, count_tokens
    from api_integration import CompressionEnabledClient
    from increase_context_window import ContextWindowExtender
except ImportError as e:
    logger.error(f"Error importing modules: {e}")
    sys.exit(1)

class TokenSolutionsManager:
    """
    Manager class that combines all token solutions.
    """
    
    def __init__(self, config=None):
        """Initialize the manager with configuration."""
        self.config = config or CONFIG
        self.setup_logging()
        
        # Initialize components based on configuration
        self._compressor = None
        self._compression_client = None
        self._context_extender = None
        
        # Monitoring data
        self.statistics = {
            "requests_processed": 0,
            "compression_applied": 0,
            "extension_applied": 0,
            "tokens_before": 0,
            "tokens_after": 0,
            "tokens_saved": 0,
            "errors": 0
        }
    
    def setup_logging(self):
        """Configure logging based on config."""
        log_level = self.config.get("monitoring", {}).get("log_level", "info").upper()
        logging.getLogger().setLevel(getattr(logging, log_level))
    
    def get_compressor(self):
        """Lazy-load the semantic compressor."""
        if self._compressor is None and self.config["semantic_compression"]["enabled"]:
            config = self.config["semantic_compression"]
            self._compressor = SemanticCompressor(
                embedding_model=config.get("embedding_model", "sentence-transformers/all-MiniLM-L6-v2"),
                summarizer_model=config.get("summarizer_model", "facebook/bart-large-cnn")
            )
        return self._compressor
    
    def get_compression_client(self):
        """Lazy-load the compression client."""
        if self._compression_client is None and self.config["semantic_compression"]["enabled"]:
            config = self.config["semantic_compression"]
            self._compression_client = CompressionEnabledClient(
                compression_ratio=config.get("default_compression_ratio", 6),
                token_limit_threshold=config.get("token_threshold", 150000),
                embedding_model=config.get("embedding_model", "sentence-transformers/all-MiniLM-L6-v2"),
                summarizer_model=config.get("summarizer_model", "facebook/bart-large-cnn")
            )
        return self._compression_client
    
    def get_context_extender(self):
        """Lazy-load the context extender."""
        if self._context_extender is None and self.config["context_extension"]["enabled"]:
            config = self.config["context_extension"]
            self._context_extender = ContextWindowExtender(
                target_context_length=config.get("target_context_length", 400000),
                api_type=config.get("api_type", "openai")
            )
        return self._context_extender
    
    def update_statistics(self, tokens_before, tokens_after, used_compression=False, used_extension=False, error=False):
        """Update usage statistics."""
        if self.config.get("monitoring", {}).get("track_token_savings", True):
            self.statistics["requests_processed"] += 1
            self.statistics["tokens_before"] += tokens_before
            self.statistics["tokens_after"] += tokens_after
            self.statistics["tokens_saved"] += max(0, tokens_before - tokens_after)
            
            if used_compression:
                self.statistics["compression_applied"] += 1
            if used_extension:
                self.statistics["extension_applied"] += 1
            if error:
                self.statistics["errors"] += 1
                
            # Save statistics if configured
            if self.config.get("monitoring", {}).get("save_statistics", True):
                stats_file = self.config.get("monitoring", {}).get("statistics_file", "token_usage_stats.jsonl")
                stats_path = os.path.join(LOG_DIR, stats_file)
                
                record = {
                    "timestamp": time.time(),
                    "tokens_before": tokens_before,
                    "tokens_after": tokens_after,
                    "tokens_saved": max(0, tokens_before - tokens_after),
                    "used_compression": used_compression,
                    "used_extension": used_extension,
                    "error": error
                }
                
                with open(stats_path, "a") as f:
                    f.write(json.dumps(record) + "\n")
    
    def process_request(self, messages=None, model=None, api_type="openai", text=None, **kwargs):
        """
        Process a request with appropriate token management strategy.
        
        Args:
            messages: List of message dictionaries for chat API
            model: Model identifier
            api_type: API provider type ('openai', 'anthropic', 'openrouter')
            text: Direct text input (alternative to messages)
            **kwargs: Additional API parameters
            
        Returns:
            API response
        """
        # Prepare content for token counting
        content = ""
        if messages:
            content = "\n".join(msg.get("content", "") for msg in messages)
        elif text:
            content = text
            # Convert to messages format if needed
            messages = [{"role": "user", "content": text}]
        
        # Count initial tokens
        tokens_before = count_tokens(content)
        logger.info(f"Initial token count: {tokens_before}")
        
        # Determine processing strategy
        use_compression = self.config["semantic_compression"]["enabled"]
        use_extension = self.config["context_extension"]["enabled"]
        fallback_to_compression = self.config["context_extension"].get("fallback_to_compression", True)
        
        try:
            # Strategy 1: Try context extension first if enabled and tokens exceed threshold
            if use_extension and tokens_before > 100000:
                logger.info("Attempting context window extension")
                extender = self.get_context_extender()
                
                try:
                    response = extender.extend_request(
                        model=model,
                        messages=messages,
                        **kwargs
                    )
                    # If successful, update statistics and return
                    self.update_statistics(tokens_before, tokens_before, used_extension=True)
                    return response
                except Exception as e:
                    logger.warning(f"Context extension failed: {e}")
                    if not fallback_to_compression or not use_compression:
                        # Re-raise if we can't fall back
                        raise
            
            # Strategy 2: Use compression (either as primary strategy or fallback)
            if use_compression:
                logger.info("Using semantic compression")
                client = self.get_compression_client()
                
                # Depending on API type, call appropriate method
                if api_type.lower() == "anthropic":
                    response = client.messages_create(
                        model=model,
                        messages=messages,
                        **kwargs
                    )
                else:  # openai or openrouter
                    response = client.chat_completions_create(
                        model=model,
                        messages=messages,
                        **kwargs
                    )
                
                # Get compressed token count from the client if available
                tokens_after = getattr(client, "_last_compressed_tokens", tokens_before // 6)
                self.update_statistics(tokens_before, tokens_after, used_compression=True)
                return response
            
            # If neither strategy is enabled or applicable, raise error
            raise ValueError("No token management strategy available or enabled.")
            
        except Exception as e:
            logger.error(f"Error processing request: {e}")
            self.update_statistics(tokens_before, tokens_before, error=True)
            raise
    
    def get_statistics(self):
        """Get current statistics."""
        return self.statistics
    
    def compress_text(self, text, compression_ratio=None):
        """Utility method to directly compress text."""
        compressor = self.get_compressor()
        if compressor is None:
            raise ValueError("Semantic compression is disabled in configuration")
            
        ratio = compression_ratio or self.config["semantic_compression"].get("default_compression_ratio", 6)
        compressed = compressor.compress(text, compression_ratio=ratio)
        
        # Update statistics
        tokens_before = count_tokens(text)
        tokens_after = count_tokens(compressed)
        self.update_statistics(tokens_before, tokens_after, used_compression=True)
        
        return compressed
    
    def extend_context(self, **kwargs):
        """Utility method to directly use context extension."""
        extender = self.get_context_extender()
        if extender is None:
            raise ValueError("Context extension is disabled in configuration")
            
        return extender.extend_request(**kwargs)

# Create singleton instance
manager = TokenSolutionsManager()

# Provide convenient access to key functionality
process_request = manager.process_request
compress_text = manager.compress_text
extend_context = manager.extend_context
get_statistics = manager.get_statistics

# OpenAI-compatible client with token solutions
class TokenManagedClient:
    """OpenAI-compatible client with built-in token management."""
    
    def __init__(self, base_client=None):
        """Initialize with optional base client."""
        self._statistics = {"calls": 0}
        
        # Import OpenAI if no base client provided
        if base_client is None:
            try:
                from openai import OpenAI
                self._base_client = OpenAI()
            except ImportError:
                logger.error("OpenAI client not found and no base client provided")
                raise
        else:
            self._base_client = base_client
    
    def chat_completions_create(self, **kwargs):
        """Override chat completions with token management."""
        self._statistics["calls"] += 1
        return process_request(**kwargs)
    
    # Add additional methods to match OpenAI client interface
    def __getattr__(self, name):
        """Pass through other attributes to base client."""
        return getattr(self._base_client, name)

if __name__ == "__main__":
    # Simple CLI usage example
    import argparse
    
    parser = argparse.ArgumentParser(description="Token Solutions Manager")
    subparsers = parser.add_subparsers(dest="command", help="Command")
    
    # Compress command
    compress_parser = subparsers.add_parser("compress", help="Compress text")
    compress_parser.add_argument("--input", "-i", required=True, help="Input file")
    compress_parser.add_argument("--output", "-o", help="Output file (default: stdout)")
    compress_parser.add_argument("--ratio", "-r", type=int, help="Compression ratio")
    
    # Extend command
    extend_parser = subparsers.add_parser("extend", help="Use context extension")
    extend_parser.add_argument("--input", "-i", required=True, help="Input file")
    extend_parser.add_argument("--model", "-m", required=True, help="Model to use")
    extend_parser.add_argument("--output", "-o", help="Output file (default: stdout)")
    
    # Stats command
    stats_parser = subparsers.add_parser("stats", help="Show usage statistics")
    
    args = parser.parse_args()
    
    if args.command == "compress":
        # Process compression command
        with open(args.input, "r") as f:
            text = f.read()
        
        compressed = compress_text(text, args.ratio)
        
        if args.output:
            with open(args.output, "w") as f:
                f.write(compressed)
            print(f"Compressed text written to {args.output}")
        else:
            print(compressed)
            
    elif args.command == "extend":
        # Process extend command
        with open(args.input, "r") as f:
            text = f.read()
        
        response = extend_context(
            model=args.model,
            messages=[{"role": "user", "content": text}],
            max_tokens=1000
        )
        
        if hasattr(response, "choices") and response.choices:
            result = response.choices[0].message.content
        elif hasattr(response, "content") and response.content:
            result = response.content[0].text
        else:
            result = str(response)
        
        if args.output:
            with open(args.output, "w") as f:
                f.write(result)
            print(f"Response written to {args.output}")
        else:
            print(result)
            
    elif args.command == "stats":
        # Show statistics
        stats = get_statistics()
        print("Token Solutions Usage Statistics")
        print("===============================")
        print(f"Requests processed:    {stats['requests_processed']}")
        print(f"Compression applied:   {stats['compression_applied']}")
        print(f"Extension applied:     {stats['extension_applied']}")
        print(f"Tokens before:         {stats['tokens_before']}")
        print(f"Tokens after:          {stats['tokens_after']}")
        print(f"Tokens saved:          {stats['tokens_saved']}")
        token_savings = 0
        if stats['tokens_before'] > 0:
            token_savings = (stats['tokens_saved'] / stats['tokens_before']) * 100
        print(f"Token savings:         {token_savings:.1f}%")
        print(f"Errors:                {stats['errors']}")
    else:
        parser.print_help()
